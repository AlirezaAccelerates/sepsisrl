{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Learn the physician policy\n",
    "# use ideas from MixNN-EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import _pickle as pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/state_features.txt') as f:\n",
    "    state_features = f.read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/rl_train_set_unscaled.csv')\n",
    "val_df = pd.read_csv('../data/rl_val_set_unscaled.csv')\n",
    "test_df = pd.read_csv('../data/rl_test_set_unscaled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define an action mapping - how to get an id representing the action from the (iv,vaso) tuple\n",
    "action_map = {}\n",
    "count = 0\n",
    "for iv in range(5):\n",
    "    for vaso in range(5):\n",
    "        action_map[(iv,vaso)] = count\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_action_map = {}\n",
    "for iv in range(5):\n",
    "    for vaso in range(5):\n",
    "        inv_action_map[5*iv+vaso] = [iv,vaso]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_mean = df['iv_input'].mean()\n",
    "iv_std = df['iv_input'].std()\n",
    "\n",
    "vaso_mean = df['vaso_input'].mean()\n",
    "vaso_std = df['vaso_input'].std()\n",
    "\n",
    "np.save('iv_mean.npy', iv_mean)\n",
    "np.save('iv_std.npy', iv_std)\n",
    "np.save('vaso_mean.npy', vaso_mean)\n",
    "np.save('vaso_std.npy', vaso_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['iv_input_norm'] = (df['iv_input']- iv_mean)/iv_std\n",
    "df['vaso_input_norm'] = (df['vaso_input'] - vaso_mean)/vaso_std\n",
    "\n",
    "val_df['iv_input_norm'] = (val_df['iv_input']- iv_mean)/iv_std\n",
    "val_df['vaso_input_norm'] = (val_df['vaso_input'] - vaso_mean)/vaso_std\n",
    "\n",
    "test_df['iv_input_norm'] = (test_df['iv_input']- iv_mean)/iv_std\n",
    "test_df['vaso_input_norm'] = (test_df['vaso_input'] - vaso_mean)/vaso_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist_feat = list(np.loadtxt('../data/state_features.txt', dtype=str))\n",
    "hist_feat.append('iv_input_norm')\n",
    "hist_feat.append('vaso_input_norm'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  X: (s_t-3, a_t-3, s_t-2, a_t-2,s_t-1, a_t-1, s_t )\n",
    "#  Y: (difference between next state and current state (zeros if end of trajectory), mortality)\n",
    "\n",
    "# this function pads with zeros (ie the mean) so that we still predict actions for all timesteps,\n",
    "# not just those with only 3 steps of history or more.\n",
    "hist = 3\n",
    "action_bins = 5\n",
    "def make_data_history_zeros(df_in):\n",
    "    df_in = df_in.reset_index()\n",
    "    X = []\n",
    "    Y = []\n",
    "    count_in_traj = 0\n",
    "    for count,i in enumerate(df_in.index):\n",
    "        if count % 10000 == 0 and count > 0:\n",
    "            print (count)\n",
    "        count_in_traj += 1\n",
    "        \n",
    "        # skip the last one; no next state\n",
    "        if i == df_in.index[-1]:\n",
    "            # the target is the action taken at this timestep\n",
    "            target_arr = df_in.loc[i, ['iv_input', 'vaso_input']].values\n",
    "            target = int(action_bins*target_arr[0] + target_arr[1])\n",
    "\n",
    "            Y.append(target)\n",
    "            \n",
    "            if count_in_traj >=(hist+1):                \n",
    "                # use hist_feat for old ones\n",
    "                state = df_in.loc[i-hist, hist_feat]\n",
    "                for index in range(hist-1,0,-1):\n",
    "                    state = np.hstack([state,df_in.loc[i-index, hist_feat]])\n",
    "                \n",
    "                # for current state, use state_features because we don't want to pass in the action!\n",
    "                state = np.hstack([state, df_in.loc[i, state_features]])\n",
    "                \n",
    "                X.append(state)\n",
    "            else:\n",
    "                num_zeros = (hist+1) - count_in_traj\n",
    "                num_actual = count_in_traj - 1\n",
    "                state = np.hstack([np.zeros(len(hist_feat)) for _ in range(num_zeros)])\n",
    "                for index in range(num_actual, 0, -1):\n",
    "                    state = np.hstack([state,df_in.loc[i-index, hist_feat]])\n",
    "                state = np.hstack([state, df_in.loc[i, state_features]])\n",
    "                X.append(state)             \n",
    "            # finish to avoid index error\n",
    "            break\n",
    "       \n",
    "        # if not terminal step in trajectory    \n",
    "        if df_in.loc[i, 'icustayid'] == df_in.loc[i+1, 'icustayid']:\n",
    "            # the target is the action taken at this timestep\n",
    "            target_arr = df_in.loc[i, ['iv_input', 'vaso_input']].values\n",
    "            target = int(action_bins*target_arr[0] + target_arr[1])\n",
    "\n",
    "            Y.append(target)\n",
    "            \n",
    "            if count_in_traj >=(hist+1):                \n",
    "                # use hist_feat for old ones\n",
    "                state = df_in.loc[i-hist, hist_feat]\n",
    "                for index in range(hist-1,0,-1):\n",
    "                    state = np.hstack([state,df_in.loc[i-index, hist_feat]])\n",
    "                \n",
    "                # for current state, use state_features because we don't want to pass in the action!\n",
    "                state = np.hstack([state, df_in.loc[i, state_features]])\n",
    "                \n",
    "                X.append(state)\n",
    "            else:\n",
    "                num_zeros = (hist+1) - count_in_traj\n",
    "                num_actual = count_in_traj - 1\n",
    "                state = np.hstack([np.zeros(len(hist_feat)) for _ in range(num_zeros)])\n",
    "                for index in range(num_actual, 0, -1):\n",
    "                    state = np.hstack([state,df_in.loc[i-index, hist_feat]])\n",
    "                state = np.hstack([state, df_in.loc[i, state_features]])\n",
    "                X.append(state)   \n",
    "        \n",
    "        else:\n",
    "            # the target is the action taken at this timestep\n",
    "            target_arr = df_in.loc[i, ['iv_input', 'vaso_input']].values\n",
    "            target = int(action_bins*target_arr[0] + target_arr[1])\n",
    "\n",
    "            Y.append(target)\n",
    "            \n",
    "            if count_in_traj >=(hist+1):    \n",
    "                # use hist_feat for old ones\n",
    "                state = df_in.loc[i-hist, hist_feat]\n",
    "                for index in range(hist-1,0,-1):\n",
    "                    state = np.hstack([state,df_in.loc[i-index, hist_feat]])\n",
    "                \n",
    "                # for current state, use state_features because we don't want to pass in the action!\n",
    "                state = np.hstack([state, df_in.loc[i, state_features]])\n",
    "                \n",
    "                X.append(state)\n",
    "            else:\n",
    "                num_zeros = (hist+1) - count_in_traj\n",
    "                num_actual = count_in_traj - 1\n",
    "                state = np.hstack([np.zeros(len(hist_feat)) for _ in range(num_zeros)])\n",
    "                for index in range(num_actual, 0, -1):\n",
    "                    state = np.hstack([state,df_in.loc[i-index, hist_feat]])\n",
    "                state = np.hstack([state, df_in.loc[i, state_features]])\n",
    "                X.append(state)\n",
    "                \n",
    "            #always reset the count\n",
    "            count_in_traj = 0\n",
    "\n",
    "    return np.array(X),pd.get_dummies(np.array(Y)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_sample(batch_size, features, labels):\n",
    "    idx = np.random.choice(np.arange(len(features)), batch_size)\n",
    "    return (np.vstack(features[idx]), np.vstack(labels[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "Saved train_zeros\n",
      "10000\n",
      "20000\n",
      "Saved val_zeros\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "Saved test_zeros\n"
     ]
    }
   ],
   "source": [
    "dire = 'behaviour_clone_data/'\n",
    "if not os.path.exists(dire):\n",
    "    os.makedirs(dire)\n",
    "\n",
    "if not os.path.exists(dire + 'X_train_hist_zeros.txt'):\n",
    "    train_feat_zeros, train_labels_zeros = make_data_history_zeros(df)\n",
    "    np.savetxt(dire + 'X_train_hist_zeros.txt',train_feat_zeros,fmt='%5.4f')\n",
    "    np.savetxt(dire + 'Y_train_hist_zeros.txt',train_labels_zeros,fmt='%5.4f')\n",
    "    print (\"Saved train_zeros\")\n",
    "else:\n",
    "    train_feat_zeros = np.loadtxt(dire + 'X_train_hist_zeros.txt')\n",
    "    train_labels_zeros = np.loadtxt(dire + 'Y_train_hist_zeros.txt')\n",
    "    print (\"Loaded train_zeros\")\n",
    "\n",
    "if not os.path.exists(dire + 'X_val_hist_zeros.txt'):\n",
    "    val_feat_zeros, val_labels_zeros = make_data_history_zeros(val_df)\n",
    "    np.savetxt(dire + 'X_val_hist_zeros.txt',val_feat_zeros,fmt='%5.4f')\n",
    "    np.savetxt(dire + 'Y_val_hist_zeros.txt',val_labels_zeros,fmt='%5.4f')\n",
    "    print (\"Saved val_zeros\")\n",
    "else:\n",
    "    val_feat_zeros = np.loadtxt(dire + 'X_val_hist_zeros.txt')\n",
    "    val_labels_zeros = np.loadtxt(dire + 'Y_val_hist_zeros.txt')\n",
    "    print (\"Loaded val_zeros\")\n",
    "\n",
    "if not os.path.exists(dire + 'X_test_hist_zeros.txt'):\n",
    "    test_feat_zeros, test_labels_zeros = make_data_history_zeros(test_df)\n",
    "    np.savetxt(dire + 'X_test_hist_zeros.txt',test_feat_zeros,fmt='%5.4f')\n",
    "    np.savetxt(dire + 'Y_test_hist_zeros.txt',test_labels_zeros,fmt='%5.4f')\n",
    "    print (\"Saved test_zeros\")\n",
    "else:\n",
    "    test_feat_zeros = np.loadtxt(dire + 'X_test_hist_zeros.txt')\n",
    "    test_labels_zeros = np.loadtxt(dire + 'Y_test_hist_zeros.txt')\n",
    "    print (\"Loaded test_zeros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feat = train_feat_zeros\n",
    "train_labels = train_labels_zeros\n",
    "\n",
    "val_feat = val_feat_zeros\n",
    "val_labels = val_labels_zeros\n",
    "\n",
    "test_feat = test_feat_zeros\n",
    "test_labels = test_labels_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169495, 198) (169495, 25)\n",
      "(24338, 198) (24338, 25)\n",
      "(48617, 198) (48617, 25)\n"
     ]
    }
   ],
   "source": [
    "print (train_feat.shape, train_labels.shape)\n",
    "print (val_feat.shape, val_labels.shape)\n",
    "print (test_feat.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_length = train_feat.shape[1]\n",
    "batch_size = 64\n",
    "num_actions = 25\n",
    "hidden_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the policy network here\n",
    "class PolicyModel():\n",
    "    def __init__(self):\n",
    "        self.input_feat = tf.placeholder(tf.float32, shape = [None, feature_length])\n",
    "        self.labels = tf.placeholder(tf.float32, shape = [None, num_actions])\n",
    "        self.phase = tf.placeholder(tf.bool)\n",
    "        \n",
    "        self.fc_1 = tf.contrib.layers.fully_connected(self.input_feat, 64, activation_fn=tf.nn.relu)\n",
    "#         self.bn_1 = tf.contrib.layers.batch_norm(self.fc_1, center=True, scale=True, is_training=self.phase)\n",
    "        self.fc_2 = tf.contrib.layers.fully_connected(self.fc_1 , 64, activation_fn=tf.nn.relu)\n",
    "#         self.bn_2 = tf.contrib.layers.batch_norm(self.fc_2, center=True, scale=True, is_training=self.phase)\n",
    "        \n",
    "        self.logits = tf.contrib.layers.fully_connected(self.fc_2 , num_actions, activation_fn=None)\n",
    "        self.output = tf.nn.softmax(self.logits)\n",
    "        self.reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "        self.reg_constant = 0.1 \n",
    "        \n",
    "        self.accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(self.labels, 1), tf.argmax(self.output, 1)),'float32'))\n",
    "        self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = self.logits, labels = self.labels)) + self.reg_constant*sum(self.reg_losses)\n",
    "\n",
    "        \n",
    "        self.update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(self.update_ops):\n",
    "            self.train_step = tf.train.AdamOptimizer().minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_policy(dataset,sess, mdl):\n",
    "\n",
    "    if dataset == 'train':\n",
    "        features, labels = train_feat,train_labels\n",
    "    elif dataset == 'val':\n",
    "        features, labels = val_feat,val_labels\n",
    "    elif dataset == 'test':\n",
    "        features, labels = test_feat,test_labels\n",
    "\n",
    "    \n",
    "    op = np.zeros((len(features), num_actions))\n",
    "    total_acc = 0\n",
    "    total_loss = 0\n",
    "    j = 0\n",
    "    while (j < len(features)):\n",
    "        feat = None\n",
    "        lbls = None\n",
    "        if len(features) - j < batch_size:\n",
    "            feat = features[j:-1]\n",
    "            lbls = labels[j:-1]\n",
    "        else:\n",
    "            feat = features[j:j+batch_size]\n",
    "            lbls = labels[j:j+batch_size]\n",
    "        feat = feat.reshape(len(feat), feature_length)\n",
    "        lbls = lbls.reshape(len(lbls), num_actions)\n",
    "        if j%10000 == 0: print('Processing val set indx: ', j )\n",
    "        softmax, accuracy, loss = sess.run([mdl.output, mdl.accuracy, mdl.loss], \n",
    "                                           feed_dict={mdl.input_feat : feat, mdl.phase: 0,mdl.labels: lbls})\n",
    "        total_acc += accuracy\n",
    "        op[j:j+len(feat)] = softmax\n",
    "        if len(features) - j < batch_size:\n",
    "            j = len(features)\n",
    "        else: j+=batch_size\n",
    "        final_acc = total_acc/(len(op)/batch_size)\n",
    "        total_loss += loss\n",
    "    return op, final_acc, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running default init\n",
      "Init done\n",
      "Starting training!\n",
      "Saved Model, epoch 1\n",
      "Average training loss per batch is 1.479536 and epoch is 1\n",
      "Processing val set indx:  0\n",
      "Val set loss: 512.040495 \n",
      "Saved Model, epoch 2\n",
      "Average training loss per batch is 1.273859 and epoch is 2\n",
      "Processing val set indx:  0\n",
      "Val set loss: 485.370984 \n",
      "Saved Model, epoch 3\n",
      "Average training loss per batch is 1.231285 and epoch is 3\n",
      "Processing val set indx:  0\n",
      "Val set loss: 477.474617 \n",
      "Saved Model, epoch 4\n",
      "Average training loss per batch is 1.208725 and epoch is 4\n",
      "Processing val set indx:  0\n",
      "Val set loss: 470.440508 \n",
      "Saved Model, epoch 5\n",
      "Average training loss per batch is 1.192957 and epoch is 5\n",
      "Processing val set indx:  0\n",
      "Val set loss: 467.680326 \n",
      "Saved Model, epoch 6\n",
      "Average training loss per batch is 1.181873 and epoch is 6\n",
      "Processing val set indx:  0\n",
      "Val set loss: 466.871370 \n",
      "Saved Model, epoch 7\n",
      "Average training loss per batch is 1.173027 and epoch is 7\n",
      "Processing val set indx:  0\n",
      "Val set loss: 465.856673 \n",
      "Saved Model, epoch 8\n",
      "Average training loss per batch is 1.165176 and epoch is 8\n",
      "Processing val set indx:  0\n",
      "Val set loss: 463.081644 \n",
      "Saved Model, epoch 9\n",
      "Average training loss per batch is 1.159904 and epoch is 9\n",
      "Processing val set indx:  0\n",
      "Val set loss: 461.330885 \n",
      "Saved Model, epoch 10\n",
      "Average training loss per batch is 1.153387 and epoch is 10\n",
      "Processing val set indx:  0\n",
      "Val set loss: 463.613839 \n",
      "Saved Model, epoch 11\n",
      "Average training loss per batch is 1.149140 and epoch is 11\n",
      "Processing val set indx:  0\n",
      "Val set loss: 461.444324 \n",
      "Saved Model, epoch 12\n",
      "Average training loss per batch is 1.144667 and epoch is 12\n",
      "Processing val set indx:  0\n",
      "Val set loss: 462.552096 \n",
      "Saved Model, epoch 13\n",
      "Average training loss per batch is 1.140863 and epoch is 13\n",
      "Processing val set indx:  0\n",
      "Val set loss: 461.111925 \n",
      "Saved Model, epoch 14\n",
      "Average training loss per batch is 1.137406 and epoch is 14\n",
      "Processing val set indx:  0\n",
      "Val set loss: 461.008212 \n",
      "Saved Model, epoch 15\n",
      "Average training loss per batch is 1.134010 and epoch is 15\n",
      "Processing val set indx:  0\n",
      "Val set loss: 461.605219 \n",
      "Saved Model, epoch 16\n",
      "Average training loss per batch is 1.130886 and epoch is 16\n",
      "Processing val set indx:  0\n",
      "Val set loss: 459.812913 \n",
      "Saved Model, epoch 17\n",
      "Average training loss per batch is 1.128153 and epoch is 17\n",
      "Processing val set indx:  0\n",
      "Val set loss: 459.891988 \n",
      "Saved Model, epoch 18\n",
      "Average training loss per batch is 1.125689 and epoch is 18\n",
      "Processing val set indx:  0\n",
      "Val set loss: 460.505665 \n",
      "Saved Model, epoch 19\n",
      "Average training loss per batch is 1.123248 and epoch is 19\n",
      "Processing val set indx:  0\n",
      "Val set loss: 461.129598 \n",
      "Saved Model, epoch 20\n",
      "Average training loss per batch is 1.121303 and epoch is 20\n",
      "Processing val set indx:  0\n",
      "Val set loss: 459.671692 \n",
      "Finished, getting final accuracy\n",
      "Processing val set indx:  0\n",
      "Processing val set indx:  0\n",
      "Processing val set indx:  40000\n",
      "Val set accuracy, loss:  0.596397306565 459.671691656\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "load_model = False #Whether to load a saved model.\n",
    "save_dir = \"./behaviour_clone/\"\n",
    "save_path = \"./behaviour_clone/ckpt\"#The path to save our model to.#\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "mdl = PolicyModel()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # Don't use all GPUs \n",
    "config.allow_soft_placement = True  # Enable manual control\n",
    "\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    if load_model == True:\n",
    "        print('Trying to load model...')\n",
    "        try:\n",
    "            restorer = tf.train.import_meta_graph(save_path + '.meta')\n",
    "            restorer.restore(sess, tf.train.latest_checkpoint(save_dir))\n",
    "            print (\"Model restored\")\n",
    "        except IOError:\n",
    "            print (\"No previous model found, running default init\")\n",
    "            sess.run(init)\n",
    "    else:\n",
    "        print(\"Running default init\")\n",
    "        sess.run(init)\n",
    "    print(\"Init done\")\n",
    "\n",
    "    net_loss = 0\n",
    "    net_accuracy = 0.0\n",
    "    print('Starting training!')\n",
    "    for j in range(1, num_epochs+1):\n",
    "        net_loss = 0.0\n",
    "        net_loglik = 0.0\n",
    "        inds = np.random.permutation(train_feat.shape[0])\n",
    "        start_idx = 0\n",
    "        end_idx = 0\n",
    "        while start_idx < len(train_feat):\n",
    "            end_idx = min(len(train_feat), start_idx+batch_size)\n",
    "            batch_inds = inds[start_idx:end_idx]\n",
    "            x_batch = train_feat[batch_inds]\n",
    "            y_batch = train_labels[batch_inds]\n",
    "            _, loss, accuracy = sess.run([mdl.train_step, mdl.loss, mdl.accuracy], \n",
    "                                     feed_dict={mdl.input_feat : x_batch, mdl.labels: y_batch, mdl.phase: 1})\n",
    "            net_loss += loss\n",
    "            net_accuracy += accuracy\n",
    "            start_idx += batch_size\n",
    "        \n",
    "        saver.save(sess,save_path)\n",
    "        print(\"Saved Model, epoch \" + str(j))\n",
    "\n",
    "        av_loss = net_loss/(len(train_feat)/float(batch_size))\n",
    "        print(\"Average training loss per batch is %f and epoch is %d\"  % (av_loss, j))\n",
    "        val_policy, val_acc, val_loss = get_policy('val', sess, mdl)\n",
    "        print('Val set loss: %f ' % (val_loss,))\n",
    "        net_loss = 0.0\n",
    "\n",
    "    print (\"Finished, getting final accuracy\")\n",
    "    val_policy, val_acc, val_loss = get_policy('val', sess, mdl)\n",
    "    test_policy, _, _ = get_policy('test',sess, mdl)\n",
    "    print('Val set accuracy, loss: ', val_acc, val_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_selected = np.argmax(val_labels_zeros, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_pol_selected = np.argmax(val_policy, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59548853644506528"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(val_pol_selected == val_selected)/float(len(val_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:my_root]",
   "language": "python",
   "name": "conda-env-my_root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
