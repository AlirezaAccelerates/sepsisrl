{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train_zeros\n",
      "Loaded val_zeros\n",
      "Loaded test_zeros\n"
     ]
    }
   ],
   "source": [
    "dire = 'mixnn_em_data/'\n",
    "train_feat_zeros = np.loadtxt(dire + 'X_train_hist_zeros.txt')\n",
    "train_labels_zeros = np.loadtxt(dire + 'Y_train_hist_zeros.txt')\n",
    "print (\"Loaded train_zeros\")\n",
    "\n",
    "val_feat_zeros = np.loadtxt(dire + 'X_val_hist_zeros.txt')\n",
    "val_labels_zeros = np.loadtxt(dire + 'Y_val_hist_zeros.txt')\n",
    "print (\"Loaded val_zeros\")\n",
    "\n",
    "test_feat_zeros = np.loadtxt(dire + 'X_test_hist_zeros.txt')\n",
    "test_labels_zeros = np.loadtxt(dire + 'Y_test_hist_zeros.txt')\n",
    "print (\"Loaded test_zeros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24338, 198) (24338, 25)\n"
     ]
    }
   ],
   "source": [
    "print(val_feat_zeros.shape, val_labels_zeros.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_action_map = {}\n",
    "for iv in range(5):\n",
    "    for vaso in range(5):\n",
    "        inv_action_map[5*iv+vaso] = [iv,vaso]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define an action mapping - how to get an id representing the action from the (iv,vaso) tuple\n",
    "action_map = {}\n",
    "count = 0\n",
    "for iv in range(5):\n",
    "    for vaso in range(5):\n",
    "        action_map[(iv,vaso)] = count\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/rl_train_data_final_cont.csv')\n",
    "val_df = pd.read_csv('../data/rl_val_data_final_cont.csv')\n",
    "test_df = pd.read_csv('../data/rl_test_data_final_cont.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feat = train_feat_zeros\n",
    "train_labels = train_labels_zeros\n",
    "\n",
    "val_feat = val_feat_zeros\n",
    "val_labels = val_labels_zeros\n",
    "\n",
    "test_feat = test_feat_zeros\n",
    "test_labels = test_labels_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the features we want to use for evaluating distance: Arterial_lactate, output_4h, meanbp, diabp,\n",
    "# chloride, paO2 fiO2, hb, adm_weight, age, sofa.\n",
    "# the ones loaded in the numpy arrays are scaled to zero mean, unit variance (so they're at the same scale)\n",
    "# we have data for t, t-1, t-2, t-3. have a time weighting: geometric series with ratio r_time\n",
    "# Weight the features according to this mapping: Arterial_lactate: 1, sofa:1, output4h: 1, *bp:1, chloride: 0.7, \n",
    "# pa02fi02: 0.7, hb: 0.7, adm_weight: 0.7, age: 0.7 \n",
    "# TGet the indices into the array and construct the multiplication factor for the euclidean distance\n",
    "# extract the rel components. Get pairwise squared distance. Multiply by fixed weighting array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features_for_dist = 10\n",
    "hist = 3\n",
    "time_weight_arr = np.ones((hist+1) * num_features_for_dist)\n",
    "r_time = 0.5\n",
    "time_weight_arr[num_features_for_dist:] *= 0.5\n",
    "time_weight_arr[2*num_features_for_dist:] *= 0.5\n",
    "time_weight_arr[3*num_features_for_dist:] *= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# indices: [lactate, sofa, output4h, meanbp, diabp, chloreide, pa02fi02, hb, weight, age]\n",
    "rel_feat_indices  = [152, 179, 192, 169, 159, 157, 172, 165, 187, 188]\n",
    "# feat_weighting = np.array([10, 0.7, 10, 5, 5, 0.7, 0.7, 0.7, 0.7, 0.7]*4)\n",
    "feat_weighting = np.array([0, 10, 0, 0, 0, 0, 0, 0, 0, 0]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rel_f_copy = rel_feat_indices.copy()\n",
    "for i in range(1,4):\n",
    "    new_arr = [j - 50*i for j in rel_f_copy]\n",
    "    rel_feat_indices += new_arr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rel_feat_indices = np.array(rel_feat_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def physio_distance(arr1, arr2):\n",
    "    rel_feat_distance = (arr1[rel_feat_indices] - arr2[rel_feat_indices])**2\n",
    "    dist = np.sum(time_weight_arr*feat_weighting*rel_feat_distance)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def physio_distance2(arr1, arr2):\n",
    "    weights = np.ones(len(arr1))\n",
    "    # weight sofa more\n",
    "#     weights[179] = 5\n",
    "    return np.sum((weights*(arr1 - arr2))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kdt = KDTree(train_feat[:100], leaf_size=30, metric='pyfunc', metric_params={\"func\":physio_distance})\n",
    "# bt = sklearn.neighbors.BallTree(train_feat,leaf_size=40, metric=physio_distance)\n",
    "# bt1 = sklearn.neighbors.BallTree(train_feat,leaf_size=10000, metric=physio_distance)\n",
    "bt2 = sklearn.neighbors.BallTree(train_feat,leaf_size=100, metric=physio_distance2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampled_ids = np.random.choice(len(val_feat), 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "# to assess the metric, iterate over the val set and get accuracy of labels\n",
    "val_labels_argmaxed = np.argmax(val_labels, axis=1)\n",
    "tot = len(val_labels_argmaxed)\n",
    "correct = 0\n",
    "dists, inds = bt1.query(val_feat[sampled_ids], k=100)\n",
    "for i, sampled_id in enumerate(sampled_ids):\n",
    "#     dist, ind = bt.query(val_x_.reshape(1,-1), k=100)\n",
    "    dist = dists[i]\n",
    "    ind = inds[i]\n",
    "#     val_x_actions = np.argmax(train_labels[np.squeeze(ind)], axis=1)\n",
    "    val_x_actions = np.argmax(train_labels[ind], axis=1)\n",
    "    acs, counts = np.unique(val_x_actions, return_counts=True)\n",
    "    emp_prob = 0.1*np.ones(25)\n",
    "    emp_prob[acs] += counts\n",
    "    pred = np.argmax(emp_prob)\n",
    "    if pred == val_labels_argmaxed[sampled_id]:\n",
    "        correct += 1\n",
    "    if i % 1000 == 0 and i > 0:\n",
    "        print(\"Count %d\" % i)\n",
    "print(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n"
     ]
    }
   ],
   "source": [
    "# to assess the metric, iterate over the val set and get accuracy of labels\n",
    "val_labels_argmaxed = np.argmax(val_labels, axis=1)\n",
    "tot = len(val_labels_argmaxed)\n",
    "correct = 0\n",
    "# sampled_ids = np.random.choice(len(val_feat), 100)\n",
    "dists, inds = bt2.query(val_feat[sampled_ids], k=50)\n",
    "for i, sampled_id in enumerate(sampled_ids):\n",
    "#     dist, ind = bt.query(val_x_.reshape(1,-1), k=100)\n",
    "    dist = dists[i]\n",
    "    ind = inds[i]\n",
    "#     val_x_actions = np.argmax(train_labels[np.squeeze(ind)], axis=1)\n",
    "    val_x_actions = np.argmax(train_labels[ind], axis=1)\n",
    "    acs, counts = np.unique(val_x_actions, return_counts=True)\n",
    "    emp_prob = 0.1*np.ones(25)\n",
    "    emp_prob[acs] += counts\n",
    "    pred = np.argmax(emp_prob)\n",
    "    if pred == val_labels_argmaxed[sampled_id]:\n",
    "        correct += 1\n",
    "    if i % 1000 == 0 and i > 0:\n",
    "        print(\"Count %d\" % i)\n",
    "print(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn_run(leaf_size, k, dist, tot_ids,seed):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    val_labels_argmaxed = np.argmax(val_labels, axis=1)\n",
    "    correct = 0\n",
    "    \n",
    "    sampled_ids = rng.choice(len(val_feat), tot_ids)\n",
    "    \n",
    "    tree = sklearn.neighbors.BallTree(train_feat,leaf_size=leaf_size, metric=dist)\n",
    "    \n",
    "    dists, inds = tree.query(val_feat[sampled_ids], k=k)\n",
    "    \n",
    "    for i, sampled_id in enumerate(sampled_ids):\n",
    "        dist = dists[i]\n",
    "        ind = inds[i]\n",
    "        val_x_actions = np.argmax(train_labels[ind], axis=1)\n",
    "        acs, counts = np.unique(val_x_actions, return_counts=True)\n",
    "        emp_prob = 0.1*np.ones(25)\n",
    "        emp_prob[acs] += counts\n",
    "        pred = np.argmax(emp_prob)\n",
    "        if pred == val_labels_argmaxed[sampled_id]:\n",
    "            correct += 1\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 113\n",
      "Correct: 107\n",
      "Correct: 107\n",
      "Leaf size 50 , k 100, average correct 0.545000\n",
      "Correct: 113\n",
      "Correct: 107\n",
      "Correct: 107\n",
      "Leaf size 100 , k 100, average correct 0.545000\n"
     ]
    }
   ],
   "source": [
    "# investigate varying leaf size and k with euclidean distance\n",
    "settings = [[50, 100],[100,100],[1000,100],[2000,100], [5000,100], [10000,100],\n",
    "           [50, 200],[100,200],[1000,200],[2000,200], [5000,200], [10000,200],\n",
    "           [50, 500],[100,500],[1000,500],[2000,500], [5000,500], [10000,500]]\n",
    "seeds = [0,5,10]\n",
    "\n",
    "tot_ids = 200\n",
    "\n",
    "for setting in settings:\n",
    "    tot_cor = 0\n",
    "    for seed in seeds:\n",
    "        leaf_size, k = setting\n",
    "        dist = physio_distance2\n",
    "        correct = knn_run(leaf_size, k, dist, tot_ids,seed)\n",
    "        print (\"Correct: %d\"% (correct,))\n",
    "        tot_cor += correct\n",
    "    frac_correct = tot_cor / (len(seeds)*tot_ids)\n",
    "    print(\"Leaf size %d , k %d, average correct %f\" % (leaf_size, k, frac_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:my_root]",
   "language": "python",
   "name": "conda-env-my_root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
