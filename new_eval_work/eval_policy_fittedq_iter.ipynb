{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fitted Q iteration (Expected SARSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# policy_train_path = '../continuous/dqn_normal/dqn_normal_actions_train.p'\n",
    "# policy_val_path = '../continuous/dqn_normal/dqn_normal_actions_val.p'\n",
    "# policy_test_path = '../continuous/dqn_normal/dqn_normal_actions_test.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import cPickle as pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Albumin', 'Arterial_BE', 'Arterial_lactate', 'Arterial_pH', 'BUN', 'CO2_mEqL', 'Calcium', 'Chloride', 'Creatinine', 'DiaBP', 'FiO2_1', 'GCS', 'Glucose', 'HCO3', 'HR', 'Hb', 'INR', 'Ionised_Ca', 'Magnesium', 'MeanBP', 'PT', 'PTT', 'PaO2_FiO2', 'Platelets_count', 'Potassium', 'RR', 'SGOT', 'SGPT', 'SIRS', 'SOFA', 'Shock_Index', 'Sodium', 'SpO2', 'SysBP', 'Temp_C', 'Total_bili', 'WBC_count', 'Weight_kg', 'age', 'elixhauser', 'gender', 'mechvent', 'output_4hourly', 'output_total', 'paCO2', 'paO2', 're_admission', 'bloc']\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "with open('../data/state_features.txt') as f:\n",
    "    state_features = f.read().split()\n",
    "print (state_features)\n",
    "print len(state_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/rl_train_data_final_cont.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bloc</th>\n",
       "      <th>icustayid</th>\n",
       "      <th>charttime</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>elixhauser</th>\n",
       "      <th>re_admission</th>\n",
       "      <th>died_in_hosp</th>\n",
       "      <th>mortality_90d</th>\n",
       "      <th>Weight_kg</th>\n",
       "      <th>...</th>\n",
       "      <th>median_dose_vaso</th>\n",
       "      <th>max_dose_vaso</th>\n",
       "      <th>input_total_tev</th>\n",
       "      <th>input_4hourly_tev</th>\n",
       "      <th>output_total</th>\n",
       "      <th>output_4hourly</th>\n",
       "      <th>cumulated_balance_tev</th>\n",
       "      <th>vaso_input</th>\n",
       "      <th>iv_input</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>7245052800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.262712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.797351</td>\n",
       "      <td>0.939195</td>\n",
       "      <td>0.589916</td>\n",
       "      <td>0.750908</td>\n",
       "      <td>0.554500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.222560</td>\n",
       "      <td>3</td>\n",
       "      <td>7245067200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.262712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.831780</td>\n",
       "      <td>0.934543</td>\n",
       "      <td>0.674384</td>\n",
       "      <td>0.819589</td>\n",
       "      <td>0.580033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.657321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.356608</td>\n",
       "      <td>3</td>\n",
       "      <td>7245081600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.262712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833222</td>\n",
       "      <td>0.656575</td>\n",
       "      <td>0.765423</td>\n",
       "      <td>0.939329</td>\n",
       "      <td>0.555033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.367788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.452837</td>\n",
       "      <td>3</td>\n",
       "      <td>7245096000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.262712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.834033</td>\n",
       "      <td>0.603831</td>\n",
       "      <td>0.783597</td>\n",
       "      <td>0.847073</td>\n",
       "      <td>0.545700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.199099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.527957</td>\n",
       "      <td>3</td>\n",
       "      <td>7245110400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.262712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.834836</td>\n",
       "      <td>0.603831</td>\n",
       "      <td>0.794059</td>\n",
       "      <td>0.811583</td>\n",
       "      <td>0.539533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.057596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bloc  icustayid   charttime  gender       age  elixhauser  \\\n",
       "0  0.000000          3  7245052800     0.0  0.412568         0.0   \n",
       "1  0.222560          3  7245067200     0.0  0.412568         0.0   \n",
       "2  0.356608          3  7245081600     0.0  0.412568         0.0   \n",
       "3  0.452837          3  7245096000     0.0  0.412568         0.0   \n",
       "4  0.527957          3  7245110400     0.0  0.412568         0.0   \n",
       "\n",
       "   re_admission  died_in_hosp  mortality_90d  Weight_kg    ...     \\\n",
       "0           0.0             0              1   0.262712    ...      \n",
       "1           0.0             0              1   0.262712    ...      \n",
       "2           0.0             0              1   0.262712    ...      \n",
       "3           0.0             0              1   0.262712    ...      \n",
       "4           0.0             0              1   0.262712    ...      \n",
       "\n",
       "   median_dose_vaso  max_dose_vaso  input_total_tev  input_4hourly_tev  \\\n",
       "0               0.0            0.0         0.797351           0.939195   \n",
       "1               0.0            0.0         0.831780           0.934543   \n",
       "2               0.0            0.0         0.833222           0.656575   \n",
       "3               0.0            0.0         0.834033           0.603831   \n",
       "4               0.0            0.0         0.834836           0.603831   \n",
       "\n",
       "   output_total  output_4hourly  cumulated_balance_tev  vaso_input  iv_input  \\\n",
       "0      0.589916        0.750908               0.554500         0.0       4.0   \n",
       "1      0.674384        0.819589               0.580033         0.0       4.0   \n",
       "2      0.765423        0.939329               0.555033         0.0       2.0   \n",
       "3      0.783597        0.847073               0.545700         0.0       2.0   \n",
       "4      0.794059        0.811583               0.539533         0.0       2.0   \n",
       "\n",
       "     reward  \n",
       "0  0.125000  \n",
       "1  0.657321  \n",
       "2  1.367788  \n",
       "3  1.199099  \n",
       "4  1.057596  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_df = pd.read_csv('../data/rl_val_data_final_cont.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../data/rl_test_data_final_cont.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Here we load the actions for the policy we want to evaluate into the relevant dataframes\n",
    "# policy_train = pickle.load(open(policy_train_path, \"rb\" ))\n",
    "# policy_test = pickle.load(open(policy_test_path, \"rb\" ))\n",
    "# policy_val = pickle.load(open(policy_val_path, \"rb\" ))\n",
    "\n",
    "# df['policy'] = np.array(policy_train)\n",
    "# test_df['policy'] = np.array(policy_test)\n",
    "# val_df['policy'] = np.array(policy_val)\n",
    "\n",
    "\n",
    "save_dir = './MixNN_EM/'\n",
    "train_actions = np.load(save_dir + \"cond_lik_train_dr.npy\")\n",
    "val_actions = np.load(save_dir + \"cond_lik_val_dr.npy\")\n",
    "test_actions = np.load(save_dir + \"cond_lik_test_dr.npy\")\n",
    "\n",
    "mix_comp_eval = 3 # SET THIS ACCORDINGLY\n",
    "train_actions = [np.array(list(i)) for i in train_actions[:,:,mix_comp_eval]]\n",
    "val_actions = [np.array(list(i)) for i in val_actions[:,:,mix_comp_eval]]\n",
    "test_actions = [np.array(list(i)) for i in test_actions[:,:,mix_comp_eval]]\n",
    "\n",
    "df['policy'] = train_actions\n",
    "val_df['policy'] = val_actions\n",
    "test_df['policy'] = test_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fq_state_terms = copy.deepcopy(state_features)\n",
    "fq_state_terms.append('iv_input')\n",
    "fq_state_terms.append('vaso_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define an action mapping - how to get an id representing the action from the (iv,vaso) tuple\n",
    "action_map = {}\n",
    "count = 0\n",
    "for iv in range(5):\n",
    "    for vaso in range(5):\n",
    "        action_map[(iv,vaso)] = count\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "action_tuple = []\n",
    "for iv in range(5):\n",
    "    for vaso in range(5):\n",
    "        action_tuple.append([iv,vaso])\n",
    "action_tuple = np.array(action_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first define all the (s,a) pairs\n",
    "# then create (s', a') for each possible next action. This is of size (num_points*25)\n",
    "# call predict on each of these \n",
    "# reshape into (-1,25): (num_points, 25)\n",
    "# multiply elementwise by prob_actions\n",
    "# reduce sum along 1 axis to get expected Q values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_s_a(df_in):\n",
    "    cur_s_a = df_in[fq_state_terms].values\n",
    "    return cur_s_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save which indices of the df are terminal\n",
    "def find_term_indices(df_in):\n",
    "    term = []\n",
    "    df_local = df_in.reset_index()\n",
    "    for count, i in enumerate(df_local.index):\n",
    "        if count % 10000 == 0 and count > 0:\n",
    "            print \"find_term_indices, step %d\" % count\n",
    "        if i != df_local.index[-1]:\n",
    "            if df_local.loc[i, 'icustayid'] != df_local.loc[i+1, 'icustayid']:\n",
    "                term.append(count)\n",
    "        else:\n",
    "            # last state is the terminal one\n",
    "            term.append(count)\n",
    "    return np.array(term)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# construct s', a' for all a in action space\n",
    "def make_s_next_a_next(df_in):\n",
    "    df_local = df_in.reset_index()\n",
    "    s_next = df_local[fq_state_terms].values\n",
    "    initial_shape = s_next.shape\n",
    "    \n",
    "    # add padding at the end\n",
    "    s_next = np.append(s_next, [np.zeros(initial_shape[1])], axis=0)\n",
    "    # remove first elem\n",
    "    s_next = s_next[1:]  \n",
    "    \n",
    "    # tile in 0 dimension to get the different actions\n",
    "    s_next_all_actions = np.repeat(s_next, 25, axis=0)\n",
    "    \n",
    "    \n",
    "    act_tup_tiled = np.tile(action_tuple, [initial_shape[0],1])\n",
    "    \n",
    "    s_next_all_actions[:,-2:] = act_tup_tiled  \n",
    "    \n",
    "    return s_next_all_actions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_prob_actions(df_in):\n",
    "    df_local = df_in.reset_index()\n",
    "    prob = df_local['policy'].values\n",
    "    prob = np.vstack([arr for arr in prob])\n",
    "    prob = np.append(prob, [np.zeros(25)], axis=0)\n",
    "    prob = prob[1:]\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# call predict on s_next_all_actions\n",
    "# weight by prob_actions\n",
    "# zero out the terminal ones\n",
    "def make_exp_next_q(s_next_all_actions, prob_actions, term_indices, reg):\n",
    "    if reg is None:\n",
    "        return np.zeros(len(s_next_all_actions)/25)\n",
    "    else:\n",
    "        next_q = reg.predict(s_next_all_actions)\n",
    "        next_q = next_q.reshape([-1,25])\n",
    "        exp_q = np.sum(prob_actions*next_q, axis=1)\n",
    "        exp_q[term_indices] = 0\n",
    "        return exp_q       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find_term_indices, step 10000\n",
      "find_term_indices, step 20000\n",
      "find_term_indices, step 30000\n",
      "find_term_indices, step 40000\n",
      "find_term_indices, step 50000\n",
      "find_term_indices, step 60000\n",
      "find_term_indices, step 70000\n",
      "find_term_indices, step 80000\n",
      "find_term_indices, step 90000\n",
      "find_term_indices, step 100000\n",
      "find_term_indices, step 110000\n",
      "find_term_indices, step 120000\n",
      "find_term_indices, step 130000\n",
      "find_term_indices, step 140000\n",
      "find_term_indices, step 150000\n",
      "find_term_indices, step 160000\n",
      "find_term_indices, step 10000\n",
      "find_term_indices, step 20000\n",
      "find_term_indices, step 10000\n",
      "find_term_indices, step 20000\n",
      "find_term_indices, step 30000\n",
      "find_term_indices, step 40000\n"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "# train\n",
    "train_X = make_s_a(df)\n",
    "train_term_indices = find_term_indices(df)\n",
    "train_s_next_a_next = make_s_next_a_next(df)\n",
    "train_prob_actions = make_prob_actions(df)\n",
    "\n",
    "# val\n",
    "val_X = make_s_a(val_df)\n",
    "val_term_indices = find_term_indices(val_df)\n",
    "val_s_next_a_next = make_s_next_a_next(val_df)\n",
    "val_prob_actions = make_prob_actions(val_df)\n",
    "\n",
    "# test\n",
    "test_X = make_s_a(test_df)\n",
    "test_term_indices = find_term_indices(test_df)\n",
    "test_s_next_a_next = make_s_next_a_next(test_df)\n",
    "test_prob_actions = make_prob_actions(test_df)\n",
    "\n",
    "reg = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "train_X_quad = poly.fit_transform(train_X)\n",
    "val_X_quad = poly.fit_transform(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4237375, 50)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_s_next_a_next.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_s_next_a_next_quad = poly.fit_transform(train_s_next_a_next)\n",
    "val_s_next_a_next_quad = poly.fit_transform(val_s_next_a_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# New training loop with quadratic features\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "# from sklearn.svm import LinearSVR\n",
    "\n",
    "reg = None\n",
    "\n",
    "num_iters = 20\n",
    "\n",
    "gamma = 0.99\n",
    "\n",
    "for i in range(num_iters):\n",
    "    next_q = make_exp_next_q(train_s_next_a_next_quad, train_prob_actions, train_term_indices, reg)\n",
    "    train_y = df['reward'] + gamma * next_q\n",
    "    \n",
    "    # create new reg object, and then call fit on train_X and train_y\n",
    "    reg = SGDRegressor(n_iter=100)\n",
    "#     reg = LinearSVR(max_iter=1000)\n",
    "    \n",
    "    reg.fit(train_X_quad, train_y)\n",
    "\n",
    "    val_next_q  = make_exp_next_q(val_s_next_a_next_quad, val_prob_actions, val_term_indices, reg)\n",
    "    val_y = val_df['reward'] + gamma * val_next_q\n",
    "    pred = reg.predict(val_X_quad)\n",
    "    mean_error = np.mean((pred - val_y)**2)\n",
    "    print \"Mean on val set is %f, mse is %f\" % (np.mean(pred),mean_error)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean on val set is 1.033356, mse is 12.768726\n",
      "Mean on val set is 1.829905, mse is 11.086921\n",
      "Mean on val set is 2.478490, mse is 10.007288\n",
      "Mean on val set is 3.274795, mse is 9.111879\n",
      "Mean on val set is 4.103237, mse is 8.398450\n",
      "Mean on val set is 4.873719, mse is 7.864678\n",
      "Mean on val set is 5.515723, mse is 7.503094\n",
      "Mean on val set is 6.115340, mse is 7.221246\n",
      "Mean on val set is 6.628810, mse is 7.023555\n",
      "Mean on val set is 7.116841, mse is 6.867109\n",
      "Mean on val set is 7.542847, mse is 6.753096\n",
      "Mean on val set is 7.945831, mse is 6.664302\n",
      "Mean on val set is 8.346300, mse is 6.592087\n",
      "Mean on val set is 8.601751, mse is 6.554877\n",
      "Mean on val set is 8.841588, mse is 6.524314\n",
      "Mean on val set is 9.023748, mse is 6.511831\n",
      "Mean on val set is 9.221690, mse is 6.494081\n",
      "Mean on val set is 9.448315, mse is 6.480782\n",
      "Mean on val set is 9.597533, mse is 6.471679\n",
      "Mean on val set is 9.491029, mse is 6.497056\n"
     ]
    }
   ],
   "source": [
    "# New training loop\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "# from sklearn.svm import LinearSVR\n",
    "\n",
    "reg = None\n",
    "\n",
    "num_iters = 20\n",
    "\n",
    "gamma = 0.99\n",
    "\n",
    "for i in range(num_iters):\n",
    "    next_q = make_exp_next_q(train_s_next_a_next, train_prob_actions, train_term_indices, reg)\n",
    "    train_y = df['reward'] + gamma * next_q\n",
    "    \n",
    "    # create new reg object, and then call fit on train_X and train_y\n",
    "    reg = SGDRegressor(n_iter=100)\n",
    "#     reg = LinearSVR(max_iter=1000)\n",
    "    \n",
    "    reg.fit(train_X, train_y)\n",
    "\n",
    "    val_next_q  = make_exp_next_q(val_s_next_a_next, val_prob_actions, val_term_indices, reg)\n",
    "    val_y = val_df['reward'] + gamma * val_next_q\n",
    "    pred = reg.predict(val_X)\n",
    "    mean_error = np.mean((pred - val_y)**2)\n",
    "    print \"Mean on val set is %f, mse is %f\" % (np.mean(pred),mean_error)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get final preds for val and test sets\n",
    "val_q = reg.predict(val_X)\n",
    "test_q = reg.predict(test_X)\n",
    "\n",
    "np.save('val_q_learned_policy.npy', val_q)\n",
    "np.save('test_q_learned_policy.npy', test_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lr_model.pkl']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(reg, 'lr_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
